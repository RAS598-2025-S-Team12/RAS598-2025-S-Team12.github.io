{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<ul> <li>Project: Automatic Delivery Turtlebot Systems  </li> <li>Team: 12  </li> <li>Members: Sandy Lin, Alan Cheng, Yibo Yuan  </li> <li>Academic Term: Spring\u00a02025  </li> <li>University: Arizona State University  </li> <li>Course: RAS598\u202f\u2014\u202fExperimentation\u202fand\u202fDeployment\u202fof\u202fRobotic\u202fSystems  </li> <li>Instructor: Prof.\u00a0Daniel\u00a0M.\u00a0Aukes  </li> </ul>","tags":["tag1","tag2"]},{"location":"#project-overview","title":"Project Overview","text":"","tags":["tag1","tag2"]},{"location":"#scope","title":"Scope","text":"<p>This project aims to develop an automated delivery system by integrating a UR5 robotic arm with a TurtleBot. Two workstations, A and B, will be set up alongside red and blue blocks. The UR5 arm will transfer the colored blocks onto the TurtleBot, which will then identify each block\u2019s color and autonomously navigate to deliver it to the designated workstation. Through this integration, we seek to optimize the sorting and delivery workflow.</p>","tags":["tag1","tag2"]},{"location":"#data-acquisition-filtering","title":"Data\u00a0Acquisition &amp;\u202fFiltering","text":"<ul> <li>LiDAR \u2192 3\u2011D point\u2011cloud mapping and obstacle detection.  </li> <li>IMU \u2192 Motion &amp; stability feedback.  </li> <li>Camera (RGB) \u2192 Colour recognition under variable lighting.</li> </ul> <p>The LiDAR will be used to collect a 3D point cloud and convert it into a map. During testing, we ensure that the LiDAR accurately senses the environment with real-time data to generate the complete map. The IMU is evaluated to confirm that it precisely measures movement and maintains stability, which is crucial for the robot's mobility. Additionally, the camera\u2019s ability to recognize colors under various conditions will be tested. In the final demonstration, the LiDAR will be fully integrated to enable smooth navigation, ensuring that the Turtlebot moves efficiently towards workstations with the ability to avoid obstacles without collision. The IMU will be used to maintain the Turtlebot's balance and ensure stable movement during delivery tasks.</p>","tags":["tag1","tag2"]},{"location":"#interaction-rviz","title":"Interaction (RViz)","text":"<p>We will use RViz to visualize the turtlebot states, LiDAR data, environment map, tf frames, navigation goals (two workstations), the planned path generated by Nav2, and debugging in real-time.</p>","tags":["tag1","tag2"]},{"location":"#control-autonomy","title":"Control &amp;\u202fAutonomy","text":"<p>The processed sensor data enables real-time responses such as collision avoidance, stability adjustments, and immediate path corrections. For instance, the LiDAR data helps detect obstacles, while the IMU provides vital motion and balance information. At the higher level, the controller uses the refined sensor data to update path planning, ensuring the Turtlebot navigates efficiently and delivers blocks to the designated workstation based on color recognition.</p>","tags":["tag1","tag2"]},{"location":"#development-prerequisites","title":"Development\u00a0Prerequisites","text":"<ol> <li>Configure UR5\u202f\u21cc\u202fTurtleBot communication (ROS\u202f2).  </li> <li>Select an efficient path\u2011planning algorithm (A*, Dijkstra, or alternative).  </li> <li>Integrate Python libraries such as OpenCV for object detection.</li> </ol> <p>To build the system, we need to understand how communication between UR5 and TurtleBot 4 works. Choosing the most suitable path-planning algorithm is crucial for efficient TurtleBot 4 navigation and minimizing delivery time. Lastly, integrating useful Python packages like OpenCV for object detection will enhance the system's capabilities.</p>","tags":["tag1","tag2"]},{"location":"#final-demonstration","title":"Final Demonstration","text":"","tags":["tag1","tag2"]},{"location":"#resources-required","title":"Resources Required","text":"<ul> <li>UR5 arm &amp; TurtleBot\u202f4</li> <li>IMU, LiDAR, wheel encoders</li> <li>High\u2011performance workstation</li> <li>Reference projects (e.g., GitHub) &amp; course material given by Prof. Aukes.</li> </ul>","tags":["tag1","tag2"]},{"location":"#classroom-setup","title":"Classroom Setup","text":"<ul> <li>UR5 robot arm and gripper</li> <li>Small blocks (red/blue)</li> <li>Several boards make up the obstacle course. </li> <li>Enough space for robotic operation</li> </ul>","tags":["tag1","tag2"]},{"location":"#test-matrix","title":"Test Matrix","text":"<ul> <li>Robustness is evaluated under varied obstacle layouts. Accuracy metrics compare sensor data against ground truth to validate adaptability.</li> </ul> <p>We will test under several different obstacle conditions to ensure that the robot are robust enough to handle variability. Several tests will be conducted to see if the robot works accurately. Comparing the sensor data and analog outputs to real-world conditions to ensure that our designed algorithms can accurately adapt to environmental changes.</p>","tags":["tag1","tag2"]},{"location":"#impact","title":"Impact","text":"<p>This project will enhance our understanding of multi-robot communication by coordinating the UR5 robotic arm and TurtleBot 4. Building an Rviz simulation will help us simulate and test the system. Developing our own user interface will improve interaction and control. Lastly, exploring different path-planning algorithms will deepen our knowledge of autonomous navigation.</p>","tags":["tag1","tag2"]},{"location":"#advising","title":"Advising","text":"<p>Dr. Aukes serves as our advisor for this project, providing technical guidance and hardware support. With his expertise in ROS2 development, robotic motion planning, and control systems, he plays a crucial role in helping us navigate the technical challenges of integrating the UR5 robotic arm and Turtlebot. Additionally, we plan to seek further technical guidance from other experts in the field to ensure the success of our project.</p>","tags":["tag1","tag2"]},{"location":"#project-progress","title":"Project Progress","text":"","tags":["tag1","tag2"]},{"location":"#achievements","title":"Achievements","text":"","tags":["tag1","tag2"]},{"location":"#1-ur5-pickandplace","title":"1\u2002UR5 Pick\u2011and\u2011Place","text":"<p>We successfully implemented control over the UR5 robotic arm, enabling it to perform pick-and-place tasks from point A to point B.</p>","tags":["tag1","tag2"]},{"location":"#2-gui-enhancement","title":"2\u2002GUI Enhancement","text":"<p>Added an \"Origin\" button based on the previously developed GUI. After initiating the system with the \"Start\" button, pressing \"Origin\" commands the Turtlebot to move to the designated position and wait to receive colored blocks.</p> <p></p>","tags":["tag1","tag2"]},{"location":"#3-predefined-actions","title":"3\u2002Pre\u2011defined Actions","text":"<p>We successfully enabled the TurtleBot to execute predefined actions. When button A is pressed, it moves forward 3 meters and then turns left for 1 meter; when button B is pressed, it moves forward 3 meters and then turns right for 1 meter.</p>","tags":["tag1","tag2"]},{"location":"#4-initial-path-planning-nav2","title":"4\u2002Initial Path Planning (Nav2)","text":"<p>Created an initial version of path planning within ttb_nav.py, incorporating obstacle detection and avoidance using ROS2's Nav2 framework.</p>","tags":["tag1","tag2"]},{"location":"#upcoming-tasks","title":"Upcoming Tasks","text":"<ol> <li>Continuous pick\u2013deliver loop controller. Develop a controller that enables continuous round-trip operations between the UR5, the color detection positions, and the drop-off block position.</li> <li>Optimise path planning (A, Dijkstra). Optimize the current path planning logic with more advanced algorithms such as A or Dijkstra to enhance navigation efficiency and stability.</li> <li>Integrate RViz digital\u2011twin visualisation. Add RViz visualization to support real-time monitoring and build a digital twin for the delivery system.</li> <li>Full system validation.</li> </ol>","tags":["tag1","tag2"]},{"location":"#code-breakdown","title":"Code Breakdown","text":"","tags":["tag1","tag2"]},{"location":"#gui-guipy","title":"GUI (<code>gui.py</code>)","text":"<ol> <li>The <code>gui.py</code>, defines a TurtleBotGUI class that inherits from both rclpy.Node and QtWidgets.QMainWindow, integrating a PyQt5 interface with ROS2 communication.</li> <li>It creates publishers for <code>/turtlebot_state</code>, <code>/gui_cmd_vel</code>, and <code>/simple_goal</code>, and subscribers for <code>/default_vel</code>, <code>/c3_14/odom</code>, and <code>/c3_14/imu</code>, handling state, velocity commands, odometry, and IMU data.</li> <li>The GUI layout comprises a read-only logging panel, a Matplotlib canvas plotting raw and FIR-filtered linear acceleration over time, and text fields displaying current linear and angular velocities.</li> <li>Spin-box controls with Reset/Send buttons enable manual velocity entry, while large START/STOP and A/B/Origin buttons toggle operation and dispatch predefined navigation goals, each action logged with a timestamp.</li> <li>Callback methods (odom_callback, imu_callback) update velocity displays and append IMU samples to a rolling buffer; update_plot applies a moving-average filter to the latest N samples before redrawing the acceleration graph.</li> </ol>","tags":["tag1","tag2"]},{"location":"#ur5-control-nodes","title":"UR5 Control Nodes","text":"<ol> <li>The ROS2 nodes, implemented in Python, include:</li> <ul> <li> <code>move_to_position.py</code> \uff1asends trajectory commands to control robot motion.     </li> <li> <code>get_position.py</code> \uff1asubscribes and monitors robot joint states and end\u2011effector poses.     </li> </ul> <li>Publishers and subscribers involved:</li> <ul> <li>Publishes JointTrajectory messages to `/scaled_joint_trajectory_controller/joint_trajectory`.</li> <li>Subscribes to `/joint_states for joint angles`.</li> <li>Subscribes to `/tcp_pose_broadcaster/pose` for end-effector position feedback.</li> </ul> <li>Motion strategy:</li> <ul> <li>Vertical pick-and-place movements utilize linear trajectory commands (moveL) for precision.</li> <li>Horizontal movements employ joint-space trajectory commands (moveJ) for efficient operation.</li> </ul> <li>Feedback system:</li> <ul> <li>Continuously monitors joint angles and end-effector positions.</li> <li>Ensures closed-loop accuracy for task execution.</li> </ul> </ol>","tags":["tag1","tag2"]},{"location":"#ursim-physical-robot","title":"URSim &amp; Physical\u00a0Robot","text":"<ol><li>Validation environment: <ul><li>Official Universal Robots ursim_e-series simulation software validates the ROS2 node performance. </li></ul></li> <li>Physical hardware constraints: <ul><li>Simultaneous ROS2 operation of robot and gripper not feasible due to hardware limitations.</li></ul></li> <li>Alternative solution implemented: <ul><li>URP control script (ur5_control.urp) pre-developed.</li> <li> <code>load_and_run_script.py</code> \uff1acommunicates with robot via Dashboard\u00a0server. </li></ul></li> <li>Python script functionality: <ul><li>Establishes TCP socket connection to robot Dashboard server.</li> <li>Loads and executes predefined URP program.</li> <li>Enables coordinated robotic arm and gripper actions. </li></ul></li> </ol>","tags":["tag1","tag2"]},{"location":"#turtlebot-state-machine-turtlebot_statepy","title":"TurtleBot State Machine (<code>turtlebot_state.py</code>)","text":"<ol> <li>The <code>turtlebot_state.py</code> defines a TurtleBotState class that inherits from rclpy.Node, containing the logic for monitoring and publishing the robot\u2019s current action state.</li> <li>It creates a publisher on <code>/turtlebot_state</code> and two subscribers\u2014one to the same topic for echoing state updates (state_callback), and one to <code>/c3_14/cmd_vel</code> for velocity commands (vel_callback)\u2014then initializes action_in_progress, zero_cmd_time, and a 1 Hz timer (check_arrival_condition).</li> <li>The publish_state(text) method wraps text into a String message, publishes it, and logs the update; state_callback sets action_in_progress (\u201cA\u201d, \u201cB\u201d or None) based on incoming state strings.</li> <li>The vel_callback watches for consecutive zero-velocity Twist messages during an active action, stamping the first zero-command time, while non-zero commands reset that timer.</li> <li>Every second, check_arrival_condition checks if the robot has held zero velocity for more than 3 seconds during an action\u2014if so, it publishes either \u201cArrived at A\u201d or \u201cArrived at B\u201d and then clears the action state.</li> </ol>","tags":["tag1","tag2"]},{"location":"#navigation-state-machine-ttb_navpy","title":"Navigation State Machine (<code>ttb_nav.py</code>)","text":"<ol> <li>The <code>ttb_nav.py</code> defines a TtbNav class that inherits from rclpy.Node, implementing a navigation state machine which listens to <code>/turtlebot_state</code> commands and translates them into Nav2 NavigateToPose goals.</li> <li>It retrieves three parameters <code>origin_pos</code>, <code>ws1_pos</code>, <code>ws2_pos</code> as [x, y, yaw_deg] from <code>ttb_pos_point.yaml</code>, logs these goal positions, initializes an ActionClient for the <code>navigate_to_pose</code> action server, and subscribes to <code>/turtlebot_state</code>, while tracking the last sent goal with <code>current_goal_tag</code>.</li> <li>The state_cb callback strips and logs each incoming state string, ignores <code>Idle</code> or <code>AtLoad</code>, then maps \"StartReturn\"/\"Origin\" \u2192 <code>origin</code>, \"StartDelivery1\" \u2192 <code>ws1</code>, \"StartDelivery2\" \u2192 <code>ws2</code>, invoking <code>send_goal</code> only if the requested tag differs from <code>current_goal_tag</code>.</li> <li>The send_goal(pos_xyz, tag) method converts the [x, y, yaw_deg] tuple into a PoseStamped (using quaternion_from_euler for the yaw), stamps it in the map frame with the current time, logs the outgoing goal, updates <code>current_goal_tag</code>, and calls <code>send_goal_async</code> with <code>feedback_cb</code> attached.</li> <li>The feedback and result callbacks handle the rest: <code>feedback_cb</code> logs the remaining distance, <code>goal_resp_cb</code> checks acceptance (resetting the tag on rejection and chaining <code>result_cb</code>), and <code>result_cb</code> logs success, cancellation or failure, then clears <code>current_goal_tag</code> so new goals can be sent.</li> </ol>","tags":["tag1","tag2"]},{"location":"#topic-learned","title":"Topic learned","text":"","tags":["tag1","tag2"]},{"location":"#ur5-troubleshooting","title":"UR5 Troubleshooting","text":"<ol> <li>Controller initialization failure</li> <ul> <li>       Problem: Launching ur_control.launch.py resulted in the spawners being unable to contact /controller_manager/list_controllers, causing controller loading to fail.     </li> <li>       Cause:       <ol> <li>           ROS 2 relies on DDS discovery           <ul> <li>               By default Cyclone DDS advertises every participant via UDP multicast (239.255.0.1:7400). When all processes can hear this packet they automatically discover each other and open the required service channels.             </li> </ul> </li> <li> false disables all multicast traffic             <ul> <li>                 With multicast blocked, discovery packets are neither sent nor received. Unless every peer (including the local host) is listed manually, different ROS 2 processes \u2013 even on the same machine \u2013 cannot see each other, so the spawner never finds /controller_manager/list_controllers.               </li> </ul> <li> true sets the SO_DONTROUTE socket flag             <ul> <li>                 This forces Cyclone DDS to send only to directly-connected networks and to ignore any address that requires routing. In a VM or a host with several interfaces (loopback, bridge, etc.) this further prevents the participants from discovering each other.               </li> </ul> <li>             After both lines were commented out             <ul> <li>                 Multicast packets are allowed again \u2192 automatic discovery works.               </li> <li>                 Routing is permitted \u2192 packets can travel through the VM bridge and loopback.               </li> <li>                 Consequently, the spawner can reach /controller_manager/list_controllers, and the launch sequence completes successfully.               </li> </ul> </li> <li>         Solution: These two lines were commented out to restore default multicast-based discovery, allowing the controllers to load successfully.       </li> <li>Real-time scheduling not enabled</li> <ul> <li>Warning: Your system/user seems not to be setup for FIFO scheduling.</li> <li>Cause: By default, real-time scheduling is not enabled in Ubuntu, and the real-time group and related permissions are not set.</li> <li>Solution:         <ol> <li>             Add user to proper groups:             <ul> <li>                 sudo groupadd realtime                 sudo usermod -aG realtime $(whoami)                 sudo usermod -aG rtkit $(whoami)               </li> </ul> </li> <li>             Create /etc/security/limits.d/99-realtime.conf with:             <ul> <li>                 @realtime   - rtprio     99                   @realtime   - memlock    unlimited                   @realtime   - nice      -20                 </li> </ul> </li> <li>             Reboot system             <ul><li>sudo reboot</li></ul> </li> <li>             Verify group membership             <ul><li>groups $(whoami)</li></ul> </li> </ol> </li> </ul> <li>Calibration data not applied</li> <ul> <li>Problem: The robot driver starts, but the real robot\u2019s pose may deviate from the MoveIt visualization.</li> <li>Cause: The robot_calibration.yaml file is missing or not applied.</li> <li>Solution:         <ol> <li>             Run the calibration launch file:             <ul><li>ros2 launch ur_calibration calibration_correction.launch.py robot_ip:=","tags":["tag1","tag2"]},{"location":"#unresolved-tasks","title":"Unresolved Tasks","text":"# Issue Problem\u202fDescription Attempted\u202f/\u202fProposed\u202fSolution 1 Create\u202f3\u00a0Platform Sensor Failure \u2013 <code>/odom</code>, <code>/imu</code>, <code>/scan</code> not published The iRobot\u00a0Create\u202f3 platform failed to initialize properly. As a result, essential ROS\u202f2 topics such as <code>/odom</code>, <code>/imu</code>, and <code>/scan</code> were not published, thereby disabling key navigation and localization functionalities. Integrated the <code>rf2o_laser_odometry</code> package to estimate odometry from LiDAR data:<code>ros2 launch rf2o_laser_odometry rf2o_laser_odometry.launch.py laser_scan_topic:=/rpi_14/scan</code> 2 Missing <code>/odom</code> TF Frame Despite launching the odometry node, the <code>/odom</code> frame did not appear in the TF tree, which is essential for many localization and navigation stacks. Added static transform:<code>ros2 run tf2_ros static_transform_publisher 0 0 0 0 0 0 odom base_link</code>However, <code>/odom</code> still missing when verifying with <code>ros2 run tf2_tools view_frames</code>. 3 SLAM Frame Drift in RViz When executing SLAM through the <code>turtlebot4_navigation</code> stack, RViz showed growing drift between frames over time. This led to inconsistencies between the robot's estimated and actual positions, making localization unreliable. The drift likely stems from the fact that /odom was derived entirely from LiDAR-based odometry without integration of wheel encoders or IMU data. A potential remedy is to apply filtering to the LiDAR measurements\u2014removing spurious (\u201cgarbage\u201d) data\u2014to improve the accuracy of the /odom estimation. <p>Repository: https://ras598-2025-s-team12.github.io/</p>","tags":["tag1","tag2"]},{"location":"charts/","title":"Charts","text":"<pre><code>\ngraph TD\n    Start[System Start] --&gt; UR5_Pickup[UR5 randomly picks up object]\n    UR5_Pickup --&gt; Wait_Turtlebot[Wait for Turtlebot arrival]\n\n    Wait_Turtlebot --&gt;|Turtlebot arrived| Place_Object[Place object on Turtlebot platform]\n    Wait_Turtlebot --&gt;|Turtlebot not arrived| Wait_Turtlebot\n\n    Place_Object --&gt; UR5_Reset[UR5 returns to standby position]\n    UR5_Reset --&gt; Wait_Turtlebot\n\n    Place_Object --&gt; Turtlebot_Identify[Turtlebot identifies Aruco marker on object]\n    Turtlebot_Identify --&gt; Path_Planning[Turtlebot plans path to workstation based on Aruco marker]\n    Path_Planning --&gt; Navigate_Workstation[Turtlebot navigates to workstation]\n\n    Navigate_Workstation --&gt; Arrive_Workstation[Arrives at workstation]\n    Arrive_Workstation --&gt; Turtlebot_Arm_Pickup[Turtlebot's arm picks up object]\n    Turtlebot_Arm_Pickup --&gt; Place_Workstation[Object placed onto workstation]\n\n    Place_Workstation --&gt; Turtlebot_Return[Turtlebot returns to predefined location]\n    Turtlebot_Return --&gt; Wait_For_Object[Turtlebot waits for next object]\n\n    Wait_For_Object --&gt;|Next object ready| Wait_Turtlebot\n    Wait_Turtlebot --&gt;|Process completed| End[Process End]\n</code></pre>"},{"location":"timeline/","title":"Gantt Chart","text":""},{"location":"static/node_modules/mathjax/","title":"MathJax","text":""},{"location":"static/node_modules/mathjax/#beautiful-math-in-all-browsers","title":"Beautiful math in all browsers","text":"<p>MathJax is an open-source JavaScript display engine for LaTeX, MathML, and AsciiMath notation that works in all modern browsers.  It was designed with the goal of consolidating the recent advances in web technologies into a single, definitive, math-on-the-web platform supporting the major browsers and operating systems.  It requires no setup on the part of the user (no plugins to download or software to install), so the page author can write web documents that include mathematics and be confident that users will be able to view it naturally and easily.  Simply include MathJax and some mathematics in a web page, and MathJax does the rest.</p> <p>Some of the main features of MathJax include:</p> <ul> <li> <p>High-quality display of LaTeX, MathML, and AsciiMath notation in HTML pages</p> </li> <li> <p>Supported in most browsers with no plug-ins, extra fonts, or special   setup for the reader</p> </li> <li> <p>Easy for authors, flexible for publishers, extensible for developers</p> </li> <li> <p>Supports math accessibility, cut-and-paste interoperability, and other   advanced functionality</p> </li> <li> <p>Powerful API for integration with other web applications</p> </li> </ul> <p>See http://www.mathjax.org/ for additional details about MathJax, and https://docs.mathjax.org for the MathJax documentation.</p>"},{"location":"static/node_modules/mathjax/#mathjax-components","title":"MathJax Components","text":"<p>MathJax version 3 uses files called components that contain the various MathJax modules that you can include in your web pages or access on a server through NodeJS.  Some components combine all the pieces you need to run MathJax with one or more input formats and a particular output format, while other components are pieces that can be loaded on demand when needed, or by a configuration that specifies the pieces you want to combine in a custom way.  For usage instructions, see the MathJax documentation.</p> <p>Components provide a convenient packaging of MathJax's modules, but it is possible for you to form your own custom components, or to use MathJax's modules directly in a node application on a server.  There are web examples showing how to use MathJax in web pages and how to build your own components, and node examples illustrating how to use components in node applications or call MathJax modules directly.</p>"},{"location":"static/node_modules/mathjax/#whats-in-this-repository","title":"What's in this Repository","text":"<p>This repository contains only the component files for MathJax, not the source code for MathJax (which are available in a separate MathJax source repository).  These component files are the ones served by the CDNs that offer MathJax to the web.  In version 2, the files used on the web were also the source files for MathJax, but in version 3, the source files are no longer on the CDN, as they are not what are run in the browser.</p> <p>The components are stored in the <code>es5</code> directory, and are in ES5 format for the widest possible compatibility.  In the future, we may make an <code>es6</code> directory containing ES6 versions of the components.</p>"},{"location":"static/node_modules/mathjax/#installation-and-use","title":"Installation and Use","text":""},{"location":"static/node_modules/mathjax/#using-mathjax-components-from-a-cdn-on-the-web","title":"Using MathJax components from a CDN on the web","text":"<p>If you are loading MathJax from a CDN into a web page, there is no need to install anything.  Simply use a <code>script</code> tag that loads MathJax from the CDN.  E.g.,</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>See the MathJax documentation, the MathJax Web Demos, and the MathJax Component Repository for more information.</p>"},{"location":"static/node_modules/mathjax/#hosting-your-own-copy-of-the-mathjax-components","title":"Hosting your own copy of the MathJax Components","text":"<p>If you want to host MathJax from your own server, you can do so by installing the <code>mathjax</code> package using <code>npm</code> and moving the <code>es5</code> directory to an appropriate location on your server:</p> <pre><code>npm install mathjax@3\nmv node_modules/mathjax/es5 &lt;path-to-server-location&gt;/mathjax\n</code></pre> <p>Note that we are still making updates to version 2, so include <code>@3</code> when you install, since the latest chronological version may not be version 3.</p> <p>Alternatively, you can get the files via GitHub:</p> <pre><code>git clone https://github.com/mathjax/MathJax.git mj-tmp\nmv mj-tmp/es5 &lt;path-to-server-location&gt;/mathjax\nrm -rf mj-tmp\n</code></pre> <p>Then (in either case) you can use a script tag like the following:</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"&lt;url-to-your-site&gt;/mathjax/tex-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>where <code>&lt;url-to-your-site&gt;</code> is replaced by the URL to the location where you moved the MathJax files above.</p> <p>See the documentation for details.</p>"},{"location":"static/node_modules/mathjax/#using-mathjax-components-in-a-node-application","title":"Using MathJax components in a node application","text":"<p>To use MathJax components in a node application, install the <code>mathjax</code> package:</p> <pre><code>npm install mathjax@3\n</code></pre> <p>(we are still making updates to version 2, so you should include <code>@3</code> since the latest chronological version may not be version 3).</p> <p>Then require <code>mathjax</code> within your application:</p> <pre><code>require('mathjax').init({ ... }).then((MathJax) =&gt; { ... });\n</code></pre> <p>where the first <code>{ ... }</code> is a MathJax configuration, and the second <code>{ ... }</code> is the code to run after MathJax has been loaded.  E.g.</p> <pre><code>require('mathjax').init({\nloader: {load: ['input/tex', 'output/svg']}\n}).then((MathJax) =&gt; {\nconst svg = MathJax.tex2svg('\\\\frac{1}{x^2-1}', {display: true});\nconsole.log(MathJax.startup.adaptor.outerHTML(svg));\n}).catch((err) =&gt; console.log(err.message));\n</code></pre> <p>Note: this technique is for node-based application only, not for browser applications.  This method sets up an alternative DOM implementation, which you don't need in the browser, and tells MathJax to use node's <code>require()</code> command to load external modules.  This setup will not work properly in the browser, even if you webpack it or bundle it in other ways.</p> <p>See the documentation and the MathJax Node Repository for more details.</p>"},{"location":"static/node_modules/mathjax/#reducing-the-size-of-the-components-directory","title":"Reducing the Size of the Components Directory","text":"<p>Since the <code>es5</code> directory contains all the component files, so if you are only planning one use one configuration, you can reduce the size of the MathJax directory by removing unused components. For example, if you are using the <code>tex-chtml.js</code> component, then you can remove the <code>tex-mml-chtml.js</code>, <code>tex-svg.js</code>, <code>tex-mml-svg.js</code>, <code>tex-chtml-full.js</code>, and <code>tex-svg-full.js</code> configurations, which will save considerable space.  Indeed, you should be able to remove everything other than <code>tex-chtml.js</code>, and the <code>input/tex/extensions</code>, <code>output/chtml/fonts/woff-v2</code>, <code>adaptors</code>, <code>a11y</code>, and <code>sre</code> directories.  If you are using the results only on the web, you can remove <code>adaptors</code> as well.</p> <p>If you are not using A11Y support (e.g., speech generation, or semantic enrichment), then you can remove <code>a11y</code> and <code>sre</code> as well (though in this case you may need to disable the assistive tools in the MathJax contextual menu in order to avoid MathJax trying to load them when they aren't there).</p> <p>If you are using SVG rather than CommonHTML output (e.g., <code>tex-svg.js</code> rather than <code>tex-chtml.js</code>), you can remove the <code>output/chtml/fonts/woff-v2</code> directory.  If you are using MathML input rather than TeX (e.g., <code>mml-chtml.js</code> rather than <code>tex-chtml.js</code>), then you can remove <code>input/tex/extensions</code> as well.</p>"},{"location":"static/node_modules/mathjax/#the-component-files-and-pull-requests","title":"The Component Files and Pull Requests","text":"<p>The <code>es5</code> directory is generated automatically from the contents of the MathJax source repository.  You can rebuild the components using the command</p> <pre><code>npm run make-es5 --silent\n</code></pre> <p>Note that since the contents of this repository are generated automatically, you should not submit pull requests that modify the contents of the <code>es5</code> directory.  If you wish to submit a modification to MathJax, you should make a pull request in the MathJax source repository.</p>"},{"location":"static/node_modules/mathjax/#mathjax-community","title":"MathJax Community","text":"<p>The main MathJax website is http://www.mathjax.org, and it includes announcements and other important information.  A MathJax user forum for asking questions and getting assistance is hosted at Google, and the MathJax bug tracker is hosted at GitHub.</p> <p>Before reporting a bug, please check that it has not already been reported.  Also, please use the bug tracker (rather than the help forum) for reporting bugs, and use the user's forum (rather than the bug tracker) for questions about how to use MathJax.</p>"},{"location":"static/node_modules/mathjax/#mathjax-resources","title":"MathJax Resources","text":"<ul> <li>MathJax Documentation</li> <li>MathJax Components</li> <li>MathJax Source Code</li> <li>MathJax Web Examples</li> <li>MathJax Node Examples</li> <li>MathJax Bug Tracker</li> <li>MathJax Users' Group</li> </ul>"}]}